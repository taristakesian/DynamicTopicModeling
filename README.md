# Dynamic Topic Modeling

Проект реализует пайплайн для анализа текстовых данных с разбиением на временные интервалы, извлечением тем, построением графов связей и визуализацией результатов.

## Структура проекта

* `pipeline.ipynb` — основной Jupyter Notebook с реализацией пайплайна.
* `data_try.csv` - тестовые данные из Telegram с 4 темами.

## Основные этапы пайплайна

1. **Загрузка данных (Load Data)**

   * Чтение исходных текстов и метаданных.
   * Предобработка: очистка, токенизация, нормализация (pymorphy3).

2. **Модуль репрезентации (Representation Module)**

   * Вычисление эмбеддингов с помощью `SentenceTransformer`.
   * Построение словарей и матриц `gensim`.

3. **Обучение (Training)**

   * Кластеризация тем с помощью BERTopic (UMAP + HDBSCAN/KMeans).
   * Настройка параметров модели.

4. **Вычисление метрик (Metrics Computation)**

   * Оценка когерентности тем (`CoherenceModel`).

5. **Алгоритм разделения на временные интервалы (Time Interval Splitting)**

   * Определение точек разбиения по дате.
   * Формирование подпериодов.

6. **Создание представлений текстов на каждом интервале (Interval Text Representation)**

   * Функция, создающая представляения тем на интервалах.

7. **Функция ветвления для каждой темы (Topic Branching Function)**

   * Создание графа ветвления для отслеживания эволюции тем по интервалам.

8. **Построение графа связей (Graph Construction)**

   * Формирование графа, где узлы — интервалы

9. **Визуализация (Visualization)**

   * Отображение графа ветвления темы.

10. **Суммаризация (Summarization)**

    * Генерация текстового резюме по каждой теме через `transformers` или OpenAI API.

## Запуск

1. Склонируйте репозиторий:
```
git clone https://github.com/taristakesian/DynamicTopicModeling.git
cd DynamicTopicModeling
```

2. Установите зависимости:
```
pip install -r requirements.txt
```

3. Задайте переменную окружения для OpenAI API (если используется). Использование платное.
```
OPENAI\_API\_KEY="ваш\_ключ"
```
4. Запустите ноутбук:
 pipeline.ipynb